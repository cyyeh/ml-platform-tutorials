{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "import pickle\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/.pyenv/versions/3.7.9/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n",
      "MLflow tracking uri: http://mlflow:5000\n",
      "Downloading Cifar10 dataset...\n"
     ]
    }
   ],
   "source": [
    "print(f'Setting up MLflow experiment...')\n",
    "experiment_name = 'cifar10-train'\n",
    "mlflow_tracking_uri = os.getenv('MLFLOW_TRACKING_URI')\n",
    "print(f'MLflow tracking uri: {mlflow_tracking_uri}')\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f'Downloading Cifar10 dataset...')\n",
    "\n",
    "tar = tarfile.open('../data/cifar-10-python.tar.gz')\n",
    "tar.extractall(path='../data')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/tensorflow/tensorflow/blob/9011878d87bdeff932e10e2b2d35570be5ef739e/tensorflow/python/keras/datasets/cifar.py#L26\n",
    "def load_batch(fpath, label_key='labels'):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "    Arguments:\n",
    "      fpath: path the file to parse.\n",
    "      label_key: key for label data in the retrieve\n",
    "          dictionary.\n",
    "    Returns:\n",
    "      A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='bytes')\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "    data = d['data']\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "# reference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/datasets/cifar10.py#L32\n",
    "def load_data():\n",
    "    dir_name = '../data/cifar-10-batches-py'\n",
    "\n",
    "    # load train data\n",
    "    num_train_samples = 50000\n",
    "\n",
    "    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        fpath = f'{dir_name}/data_batch_{i}'\n",
    "        (x_train[(i - 1) * 10000:i * 10000, :, :, :],\n",
    "         y_train[(i - 1) * 10000:i * 10000]) = load_batch(fpath)\n",
    "\n",
    "    # load test data\n",
    "    fpath = f'{dir_name}/test_batch'\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    x_test = x_test.astype(x_train.dtype)\n",
    "    y_test = y_test.astype(y_train.dtype)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/test images...\n",
      "Neural networking training for 1 epoch...\n",
      "   1/1563 [..............................] - ETA: 0s - loss: 2.2936 - accuracy: 0.0625WARNING:tensorflow:From /home/jovyan/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1563 [..............................] - ETA: 2:04 - loss: 2.2933 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0380s vs `on_train_batch_end` time: 0.1137s). Check your callbacks.\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.5001 - accuracy: 0.4542 - val_loss: 1.2179 - val_accuracy: 0.5615\n",
      "313/313 - 3s - loss: 1.2179 - accuracy: 0.5615\n",
      "test_acc: 0.5615000128746033\n",
      "test_loss: 1.217909336090088\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f'Loading train/test images...')\n",
    "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(f'Neural networking training for 1 epoch...')\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    log_dir = os.getenv('TENSORBOARD_LOGS_DIR') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    history = model.fit(train_images,\n",
    "                        train_labels,\n",
    "                        epochs=1,\n",
    "                        validation_data=(test_images, test_labels),\n",
    "                        callbacks=[tensorboard_callback])\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "    print(f'test_acc: {test_acc}')\n",
    "    print(f'test_loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1404d6bfcc1c8060\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1404d6bfcc1c8060\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /logs/tensorboard --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
